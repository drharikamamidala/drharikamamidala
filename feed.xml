<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://drharikamamidala.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://drharikamamidala.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-29T00:47:38+00:00</updated><id>https://drharikamamidala.github.io/feed.xml</id><title type="html">blank</title><subtitle>BDS, MSHI </subtitle><entry><title type="html">From Requirements to Results: How We Simulated a EHR Vendor Evaluation</title><link href="https://drharikamamidala.github.io/blog/2025/from-requirements-to-results-how-we-simulated-a-ehr-vendor-evaluation/" rel="alternate" type="text/html" title="From Requirements to Results: How We Simulated a EHR Vendor Evaluation"/><published>2025-04-07T00:58:54+00:00</published><updated>2025-04-07T00:58:54+00:00</updated><id>https://drharikamamidala.github.io/blog/2025/from-requirements-to-results-how-we-simulated-a-ehr-vendor-evaluation</id><content type="html" xml:base="https://drharikamamidala.github.io/blog/2025/from-requirements-to-results-how-we-simulated-a-ehr-vendor-evaluation/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qGnr-z_s-pGvZ9wM-DnpcQ.png"/></figure> <p>Choosing an Electronic Health Record (EHR) system isn’t just about picking popular software. It’s about understanding what your hospital or clinic truly needs and finding a vendor that fits. In this project, we simulated a real-world vendor evaluation process — from gathering hospital needs to comparing vendor responses — to learn how hospitals choose the right EHR.</p> <p>Here’s what we learned and how you can apply the same approach.</p> <h3>Step 1: Start With the Real Problems</h3> <p>Every EHR project should begin with problems you’re trying to solve. In our case, we looked at a fictional multi specialty hospital and categorized its challenges as follows:</p> <ul><li><strong>Scheduling and Access</strong>: Long wait times, lack of self-scheduling, no reminders</li><li><strong>Clinical Workflow</strong>: Inefficient referrals, delayed inpatient handoffs</li><li><strong>Documentation and Records</strong>: Paper-based or disconnected records</li><li><strong>Billing and Finance</strong>: Manual billing and frequent claim denials</li><li><strong>Patient Engagement</strong>: Limited portal features, no mobile access</li><li><strong>Reporting and Decision Support</strong>: Lack of insights, no real-time data tracking</li></ul> <p>These categories helped define <strong>functional requirements</strong> like scheduling, referrals, patient portals, billing integration, and inpatient tracking.</p> <h3>Step 2: Translate Problems Into Detailed Requirements</h3> <p>We broke these broad needs into specific, testable features using a simple table. For example:</p> <p>Category Requirement Priority Scheduling System should allow automated appointment reminders High Patient Portal Must be mobile-friendly with multilingual support Medium Inpatient Real-time ADT (admit, discharge, transfer) tracking High Billing Insurance claim validation and automated submission High Referrals Track referral status and auto-notify patients and doctors Medium</p> <p>The clearer the requirement, the easier it is to evaluate vendors.</p> <h3>Step 3: Write the RFP (Request for Proposal)</h3> <p>With requirements finalized, we created an RFP document that included:</p> <p>An overview of the fictional hospital</p> <ul><li>A list of technical and functional needs</li><li>A proposed budget of $2.35M–$5.45M</li><li>A project timeline (up to 58 weeks)</li><li>Instructions for vendors to respond with matching details</li></ul> <p>Here’s a sample section from our RFP:</p> <blockquote><em>“The proposed EHR system must support both ambulatory and inpatient workflows, ensure regulatory compliance (HIPAA, ONC), and enable seamless interoperability with lab, pharmacy, radiology, and billing systems. Vendors must detail deployment models (cloud/on-premise), support timelines, and pricing breakdowns.”</em></blockquote> <p>This document became the official call for vendors to submit their proposals.</p> <h3>Step 4: Create and Review Vendor Responses</h3> <p>To simulate vendor evaluation, we drafted <strong>fictional responses</strong> from two major EHR vendors: <strong>Epic</strong> and <strong>Medi tech</strong>. Each included:</p> <h4>Epic Sample Response:</h4> <blockquote><em>“Epic offers an integrated platform that supports both inpatient and outpatient workflows. Key features include MyChart for patient engagement, HL7/FHIR interoperability, and advanced clinical decision support tools. Epic also integrates AI-driven early warning systems, predictive analytics for patient deterioration, and smart scheduling to reduce no-shows. Estimated licensing and implementation cost is between $2.3M–$4.9M.”</em></blockquote> <h4>Meditech Sample Response:</h4> <blockquote><em>“Meditech Expanse provides scalable EHR capabilities for mid-sized health systems. The platform includes ePrescribing, customizable workflows, and basic interoperability tools. Estimated cost ranges from $1.8M–$3.9M.”</em></blockquote> <p>These mock responses helped us analyze what hospitals typically receive during real EHR selection processes.</p> <h3>Step 5: Score and Compare Vendors</h3> <p>Next, we created a scoring matrix based on detailed templates we developed for each requirement category. Each vendor was rated on:</p> <ul><li>Functional Capabilities (clinical documentation, scheduling, referrals, etc.)</li><li>Technical Requirements (interoperability, security, infrastructure)</li><li>Operational Aspects (training, support, ease of use)</li><li>Cost and Budget Fit</li><li>Implementation Timeline</li><li>Alignment with Hospital Vision and Use Cases</li></ul> <p>We assigned weights based on how critical each area was to our fictional hospital’s needs:</p> <p>Evaluation Area Weight Epic Score Meditech Score Functional Fit 35% 33 28 Technical Capability 25% 23 21 Support &amp; Training 10% 9 9 Cost Effectiveness 10% 7 9 Timeline &amp; Delivery 10% 9 8 Reputation &amp; Fit 10% 9 8</p> <p>💡 <em>Note: Scores are based on weighted evaluations. Each vendor was rated across sub-criteria within each category, with final points scaled to match the assigned weight (e.g., Functional Fit scores out of 35, Technical Capability out of 25, etc.).</em> This structured, point-based approach helped make our decision objective, data-driven, and defensible.</p> <h3>Final Result: Data Over Assumptions</h3> <p>This simulation helped us understand that <strong>data-driven decisions</strong> are better than assumptions or brand reputation alone. A structured evaluation process helps identify the vendor that truly fits the organization’s goals.</p> <h3>Key Takeaways</h3> <ul><li>Start with real problems, not just features.</li><li>Break requirements into simple, testable items.</li><li>Use scoring to compare vendors fairly.</li><li>A well-written RFP saves time and avoids confusion.</li><li>Simulating vendor responses gives great practice for real-world work.</li></ul> <p>This project helped us understand how hospitals select EHRs — and how any healthcare or IT team can use the same method.</p> <p><em>Written as a learning experience for healthcare and IT students exploring how EHR vendor evaluations are done.</em></p> <h3>Acknowledgments</h3> <p>This simulation project was completed as part of an academic exercise. I would like to thank:</p> <ul><li><strong>Prof. Tobi Ojo</strong>, for invaluable guidance and feedback throughout the project.</li></ul> <p><strong>Team Members (including me): </strong>Akhila, Tejaswi, Amala, Harshitha</p> <p>Each member contributed to different parts of the project including requirement analysis, RFP drafting, vendor response creation, and final evaluation.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=af141d4cdd36" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>